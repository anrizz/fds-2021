---
title: 'Assigment 1'
author: "Andri Rizzi"
date: "14.06.2021"
output:
  pdf_document:
    toc: yes
  html_document:
    code_folding: hide
    fig_height: 6
    highlight: tango
    theme: spacelab
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
editor_options:
  chunk_output_type: console
---



```{r knitr_init, echo=TRUE, cache=FALSE, warning=FALSE}
library(knitr)

### Global options
options(max.print="150")
opts_chunk$set(echo=TRUE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
rm(list = ls())
```

# Assignment 1: RMarkdown

* Change the author of this file to your name.
- To solve that I just had to replace the name. 

* Change the settings of this file so that the code is by shown by default. 
- I had to change echo=False in the chunk above to echo=TRUE


# Assignment 2: Import dataset

In the data folder of this the first exercise session ("data/") you will find two datasets (twitter.Rda, guardian.Rda). These two datasets contain information retrieved from the respective APIs of the two platforms in 2020:

 * **guardian.Rda**: articles of The Guardian obtained via its API. Contains information about an article, its author and its content.
 * **twitter.Rda**: Tweets published by the account 'guardian' on Twitter. These Tweets often represent links to articles of The Guardian and contain information about the reactions to those articles (such as how many people favorited these statuses).
 
**Assignment:** Find a suitable variable to merge these two datasets on and then create a combined dataset that contains information about both the article characteristics (from the Guardian API) and the Twitter characteristics. Then use the **merge()** command to merge the two datasets. Report how many observations you lose from each original dataset.

First Step: Load datasets into R

```{r,echo=TRUE}
rm(list = ls())
load("~/Desktop/Unterlagen/1 - Universität/2 - Master /1 - Politikwissenschaft/2 - Semester/Foundations of Data Science for Social Scientists/excersises/1/guardian.Rda")
head(guardian)
dim(guardian)

rm(list = ls())
load("~/Desktop/Unterlagen/1 - Universität/2 - Master /1 - Politikwissenschaft/2 - Semester/Foundations of Data Science for Social Scientists/excersises/1/twitter.Rda")
head(twitter)
dim(twitter)
```

2. Step: Get overview 
```{r,echo=TRUE}
str(guardian)
str(twitter)
```

3. Step Merge the two variables. I concluded that it would be best to merge the datasets on the basis of the URL. In the dataset guardian this would be the variable link and in the dataset twitter link as well. 

```{r,echo=TRUE}


merged <- merge(guardian, twitter, by = "link", all = FALSE)
plot(guardian$link ~ twitter$link, xlab = "link", ylab = "link")
str(merged)
```
To answer the last question we only have to substract the number of the observations from the merged datasetz with the others. Therefore we lost (3493-2498=995) 995 Observations from the guardian-dataset and (4077-2498=1579) 1579 observations from the twitter-dataset. This simple calculations is feasible since we made sure that only observations with the same link in both datasets are  in the merged-version

# Assignment 3: Insights

In the combined data you just generated in the previous question, please answer the following questions. (Note: If you could not solve the prior assignments, you may here continue with the "combined.Rda" file from the "data/" folder in the first exercise.)

 * Does the page number where the article occurred in the Guardian newspaper have a positive or negative correlation to the number of retweets an article received?
 * Do articles about music in our sample data get more or less frequently liked ("favorited") than sport articles?
 
 